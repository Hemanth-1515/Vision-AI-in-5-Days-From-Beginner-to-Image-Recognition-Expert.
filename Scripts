/* ALL CODE SCRIPTS */ 
import os
os.listdir()
from google.colab import files

uploaded = files.upload()  # Select all 4 MNIST files from your PC
import os
os.listdir()
import numpy as np
import struct
import cv2
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

# --- Functions to load MNIST images & labels ---
def load_idx_images(filename):
    with open(filename, 'rb') as f:
        magic, num_images, rows, cols = struct.unpack(">IIII", f.read(16))
        data = np.frombuffer(f.read(), dtype=np.uint8)
        return data.reshape(num_images, rows, cols)

def load_idx_labels(filename):
    with open(filename, 'rb') as f:
        magic, num_items = struct.unpack(">II", f.read(8))
        return np.frombuffer(f.read(), dtype=np.uint8)

# --- Load dataset ---
X_train = load_idx_images("train-images.idx3-ubyte")
y_train = load_idx_labels("train-labels.idx1-ubyte")
X_test = load_idx_images("t10k-images.idx3-ubyte")
y_test = load_idx_labels("t10k-labels.idx1-ubyte")

print("Training set:", X_train.shape, y_train.shape)
print("Test set:", X_test.shape, y_test.shape)
print("Pixel range before normalization:", X_train.min(), "to", X_train.max())

X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0
print("Pixel range after normalization:", X_train.min(), "to", X_train.max())

img_original = X_train[0]
img_resized = cv2.resize(img_original, (64, 64))
print("Original size:", img_original.shape)
print("Resized size:", img_resized.shape)

plt.figure(figsize=(5,5))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(X_train[i], cmap='gray')
    plt.title(f"Label: {y_train[i]}")
    plt.axis('off')
plt.show()

img_uint8 = (X_train[0] * 255).astype('uint8')
cv2_imshow(img_uint8)

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

# Load dataset
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

# Normalize pixel values (0–255) → (0–1)
train_images = train_images / 255.0
test_images = test_images / 255.0

# Reshape for CNN (28x28 → 28x28x1)
train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))
test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))

print("Train shape:", train_images.shape)
print("Test shape:", test_images.shape)

model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')  # 10 classes for digits 0–9
])

model.summary()

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_images, train_labels,
    epochs=5,                 # Try increasing for better accuracy
    validation_data=(test_images, test_labels)
)

plt.figure(figsize=(12,4))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Accuracy over Epochs')

# Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss over Epochs')

plt.show()

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f"\n✅ Test accuracy: {test_acc * 100:.2f}%")

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize
y_train = y_train.flatten()
y_test = y_test.flatten()

datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)
datagen.fit(x_train)

model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')  # 10 classes in CIFAR-10
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(datagen.flow(x_train, y_train, batch_size=64),
                    epochs=10,
                    validation_data=(x_test, y_test))

y_pred_probs = model.predict(x_test)
y_pred = np.argmax(y_pred_probs, axis=1)

print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

plt.figure(figsize=(12,5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend()
plt.title('Accuracy over Epochs')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend()
plt.title('Loss over Epochs')

plt.show()

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Training data
train_images_path = "train-images.idx3-ubyte"
train_labels_path = "train-labels.idx1-ubyte"

# Validation (or test) data
test_images_path = "t10k-images.idx3-ubyte"
test_labels_path = "t10k-labels.idx1-ubyte"
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Normalize for custom CNN
train_images_cnn = train_images / 255.0
test_images_cnn = test_images / 255.0

# Expand dims for CNN input
train_images_cnn = np.expand_dims(train_images_cnn, -1)
test_images_cnn = np.expand_dims(test_images_cnn, -1)

# One-hot encode labels
train_labels_cnn = to_categorical(train_labels, 10)
test_labels_cnn = to_categorical(test_labels, 10)

# Convert grayscale to RGB (MobileNet needs 3 channels)
train_images_mnet = np.repeat(train_images[..., np.newaxis], 3, axis=-1)
test_images_mnet = np.repeat(test_images[..., np.newaxis], 3, axis=-1)

# Resize to MobileNetV2 input size (96x96 for speed)
train_images_mnet = tf.image.resize(train_images_mnet, [96, 96])
test_images_mnet = tf.image.resize(test_images_mnet, [96, 96])

# Preprocess
train_images_mnet = preprocess_input(train_images_mnet)
test_images_mnet = preprocess_input(test_images_mnet)

train_labels_mnet = to_categorical(train_labels, 10)
test_labels_mnet = to_categorical(test_labels, 10)

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
import matplotlib.pyplot as plt
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
batch_size = 64

train_images_cnn = (train_images / 255.0)[..., np.newaxis]
test_images_cnn = (test_images / 255.0)[..., np.newaxis]

train_labels_cnn = to_categorical(train_labels, 10)
test_labels_cnn = to_categorical(test_labels, 10)

train_ds_cnn = tf.data.Dataset.from_tensor_slices((train_images_cnn, train_labels_cnn)).batch(batch_size)
test_ds_cnn = tf.data.Dataset.from_tensor_slices((test_images_cnn, test_labels_cnn)).batch(batch_size)
train_images_mnet = np.repeat(train_images[..., np.newaxis], 3, axis=-1)
test_images_mnet = np.repeat(test_images[..., np.newaxis], 3, axis=-1)

# Resize + preprocess in tf.data pipeline (saves RAM)
def preprocess_mnet(image, label):
    image = tf.image.resize(image, [96, 96])
    image = preprocess_input(image)
    return image, label

train_labels_mnet = to_categorical(train_labels, 10)
test_labels_mnet = to_categorical(test_labels, 10)

train_ds_mnet = tf.data.Dataset.from_tensor_slices((train_images_mnet, train_labels_mnet)) \
    .map(preprocess_mnet, num_parallel_calls=tf.data.AUTOTUNE) \
    .batch(batch_size) \
    .prefetch(tf.data.AUTOTUNE)

test_ds_mnet = tf.data.Dataset.from_tensor_slices((test_images_mnet, test_labels_mnet)) \
    .map(preprocess_mnet, num_parallel_calls=tf.data.AUTOTUNE) \
    .batch(batch_size) \
    .prefetch(tf.data.AUTOTUNE)
cnn_model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

cnn_model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

print("Training Custom CNN...")
history_cnn = cnn_model.fit(train_ds_cnn,
                            validation_data=test_ds_cnn,
                            epochs=5)
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))
base_model.trainable = False  # Freeze base layers

mnet_model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(10, activation='softmax')
])

mnet_model.compile(optimizer='adam',
                   loss='categorical_crossentropy',
                   metrics=['accuracy'])

print("Training MobileNetV2 (Frozen Base)...")
history_mnet = mnet_model.fit(train_ds_mnet,
                              validation_data=test_ds_mnet,
                              epochs=5)
cnn_acc = history_cnn.history['val_accuracy'][-1]
mnet_acc = history_mnet.history['val_accuracy'][-1]
improvement = (mnet_acc - cnn_acc) * 100

print("\n📊 Comparison:")
print(f"Custom CNN Accuracy: {cnn_acc*100:.2f}%")
print(f"MobileNetV2 Accuracy: {mnet_acc*100:.2f}%")
print(f"Improvement: {improvement:.2f}%")
plt.figure(figsize=(10,5))
plt.plot(history_cnn.history['val_accuracy'], label='Custom CNN')
plt.plot(history_mnet.history['val_accuracy'], label='MobileNetV2')
plt.xlabel("Epochs")
plt.ylabel("Validation Accuracy")
plt.title("Model Comparison")
plt.legend()
plt.show()
